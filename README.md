# Modelado y PredicciÃ³n del Consumo EnergÃ©tico en ClÃºsteres HPC

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto de Trabajo de Fin de Grado (TFG) en IngenierÃ­a InformÃ¡tica tiene como objetivo desarrollar un sistema completo para el modelado y predicciÃ³n del consumo energÃ©tico en clÃºsteres de computaciÃ³n de alto rendimiento (HPC) mediante el anÃ¡lisis de patrones tÃ©rmicos y carga de trabajo.

### ğŸ¯ Objetivos Principales

- **RecolecciÃ³n de mÃ©tricas**: Capturar datos tÃ©rmicos, de carga de trabajo y consumo energÃ©tico de jobs HPC
- **Modelado predictivo**: Desarrollar algoritmos de machine learning para predecir el consumo energÃ©tico por job
- **VisualizaciÃ³n avanzada**: Crear dashboards interactivos con Grafana para anÃ¡lisis de correlaciones
- **OptimizaciÃ³n energÃ©tica**: Proporcionar recomendaciones inteligentes para la colocaciÃ³n eficiente de jobs

## ğŸ—ï¸ Arquitectura del Sistema

### Infraestructura Base
- **Proxmox**: Plataforma de virtualizaciÃ³n con CPU passthrough
- **Slurm**: Gestor de colas y recursos HPC
- **Prometheus**: Sistema de monitorizaciÃ³n y alertas
- **TimescaleDB**: Base de datos optimizada para series temporales
- **Grafana**: Plataforma de visualizaciÃ³n y dashboards

### Componentes del ClÃºster
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Slurm Head    â”‚    â”‚  Compute Node 1 â”‚    â”‚  Compute Node 2 â”‚
â”‚   Controller    â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚                 â”‚    â”‚  - Node Exporterâ”‚    â”‚  - Node Exporterâ”‚
â”‚ - Prometheus    â”‚    â”‚  - Thermal Mon. â”‚    â”‚  - Thermal Mon. â”‚
â”‚ - TimescaleDB   â”‚    â”‚  - Job Scripts  â”‚    â”‚  - Job Scripts  â”‚
â”‚ - Grafana       â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Dataset y MÃ©tricas

Cada job ejecutado genera las siguientes mÃ©tricas:

| MÃ©trica | DescripciÃ³n | Unidad |
|---------|-------------|--------|
| `timestamp` | Marca temporal de ejecuciÃ³n | Unix timestamp |
| `job_id` | Identificador Ãºnico del job | String |
| `job_type` | Tipo de carga (CPU/IO/Mixed) | Enum |
| `node_temp_avg` | Temperatura media del nodo | Â°C |
| `node_temp_peak` | Pico tÃ©rmico durante ejecuciÃ³n | Â°C |
| `duration` | DuraciÃ³n total del job | Segundos |
| `cpu_freq_avg` | Frecuencia media de CPU | MHz |
| `energy_consumption` | Consumo energÃ©tico estimado | Watts |
| `memory_usage` | Uso de memoria promedio | MB |
| `cpu_utilization` | UtilizaciÃ³n de CPU promedio | % |

## ğŸ—‚ï¸ Estructura del Proyecto

```
hpc-energy-model/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ installation.md
â”‚   â””â”€â”€ api-reference.md
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ proxmox/
â”‚   â”‚   â”œâ”€â”€ vm-templates/
â”‚   â”‚   â””â”€â”€ network-config/
â”‚   â”œâ”€â”€ slurm/
â”‚   â”‚   â”œâ”€â”€ slurm.conf
â”‚   â”‚   â”œâ”€â”€ slurmdbd.conf
â”‚   â”‚   â””â”€â”€ job-templates/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â”‚   â””â”€â”€ rules/
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ dashboards/
â”‚       â””â”€â”€ provisioning/
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ exporters/
â”‚   â”‚   â”œâ”€â”€ thermal-exporter/
â”‚   â”‚   â”œâ”€â”€ job-exporter/
â”‚   â”‚   â””â”€â”€ energy-exporter/
â”‚   â””â”€â”€ collectors/
â”œâ”€â”€ workloads/
â”‚   â”œâ”€â”€ cpu-intensive/
â”‚   â”œâ”€â”€ io-intensive/
â”‚   â”œâ”€â”€ mixed-workloads/
â”‚   â””â”€â”€ benchmark-suite/
â”œâ”€â”€ ml-models/
â”‚   â”œâ”€â”€ data-preprocessing/
â”‚   â”œâ”€â”€ feature-engineering/
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ inference/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ energy-predictor/
â”‚   â”œâ”€â”€ job-scheduler/
â”‚   â””â”€â”€ recommendation-engine/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup/
â”‚   â”œâ”€â”€ data-collection/
â”‚   â””â”€â”€ automation/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ performance/
â””â”€â”€ results/
    â”œâ”€â”€ datasets/
    â”œâ”€â”€ models/
    â””â”€â”€ reports/
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
- Proxmox VE 7.0+
- Python 3.9+
- Docker y Docker Compose
- Al menos 16GB RAM y 4 cores CPU

### ConfiguraciÃ³n RÃ¡pida

1. **Clonar el repositorio**:
   ```bash
   git clone https://github.com/psantana5/hpc-energy-model.git
   cd hpc-energy-model
   ```

2. **Instalar dependencias**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurar infraestructura**:
   ```bash
   ./scripts/setup/deploy-infrastructure.sh
   ```

4. **Inicializar servicios**:
   ```bash
   docker-compose up -d
   ```

## ğŸ“ˆ MetodologÃ­a de Desarrollo

### Fase 1: PreparaciÃ³n del Entorno (Semanas 1-3)
- [ ] ConfiguraciÃ³n de VMs en Proxmox
- [ ] InstalaciÃ³n y configuraciÃ³n de Slurm
- [ ] Despliegue de stack de monitorizaciÃ³n
- [ ] Desarrollo de exportadores personalizados

### Fase 2: RecolecciÃ³n de Datos (Semanas 4-6)
- [ ] ImplementaciÃ³n de workloads sintÃ©ticos
- [ ] AutomatizaciÃ³n de ejecuciÃ³n de jobs
- [ ] ValidaciÃ³n de mÃ©tricas recolectadas
- [ ] GeneraciÃ³n de dataset inicial

### Fase 3: AnÃ¡lisis y Modelado (Semanas 7-10)
- [ ] AnÃ¡lisis exploratorio de datos
- [ ] IngenierÃ­a de caracterÃ­sticas
- [ ] Entrenamiento de modelos predictivos
- [ ] ValidaciÃ³n y optimizaciÃ³n de modelos

### Fase 4: VisualizaciÃ³n y Recomendaciones (Semanas 11-12)
- [ ] Desarrollo de dashboards en Grafana
- [ ] ImplementaciÃ³n de motor de recomendaciones
- [ ] API para predicciones en tiempo real
- [ ] DocumentaciÃ³n y presentaciÃ³n final

## ğŸ”§ TecnologÃ­as Utilizadas

- **OrquestaciÃ³n**: Slurm, Proxmox
- **MonitorizaciÃ³n**: Prometheus, Node Exporter, exportadores personalizados
- **Base de Datos**: TimescaleDB, PostgreSQL
- **VisualizaciÃ³n**: Grafana, Jupyter Notebooks
- **Machine Learning**: scikit-learn, pandas, numpy
- **Desarrollo**: Python, Bash, Docker
- **Testing**: pytest, unittest

## ğŸ“Š Resultados Esperados

- **Dataset completo** con +10,000 jobs ejecutados
- **Modelo predictivo** con precisiÃ³n >85% en consumo energÃ©tico
- **Dashboard interactivo** para anÃ¡lisis en tiempo real
- **Motor de recomendaciones** para optimizaciÃ³n de scheduling
- **DocumentaciÃ³n tÃ©cnica** completa del sistema

## ğŸ¤ ContribuciÃ³n

Este proyecto estÃ¡ desarrollado como TFG. Para sugerencias o mejoras:

1. Fork del repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit de cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ‘¨â€ğŸ’» Autor

**[Tu Nombre]** - Estudiante de IngenierÃ­a InformÃ¡tica  
Universidad: [Nombre de tu Universidad]  
Email: [tu-email@universidad.edu]

## ğŸ™ Agradecimientos

- Director/a del TFG: [Nombre del director]
- Departamento de [Nombre del departamento]
- Comunidad open source de Slurm, Prometheus y Grafana

---

*Proyecto desarrollado como Trabajo de Fin de Grado en IngenierÃ­a InformÃ¡tica*