# Fluentd Configuration for HPC Energy Model
# Advanced logging aggregation and processing

# Input sources
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  tag docker.*
</source>

# Docker container logs
<source>
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  format json
  time_key time
  time_format %Y-%m-%dT%H:%M:%S.%NZ
</source>

# HPC Energy API logs
<source>
  @type tail
  path /var/log/hpc/api/*.log
  pos_file /var/log/fluentd-api.log.pos
  tag hpc.api
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S
</source>

# Slurm job logs
<source>
  @type tail
  path /var/log/slurm/*.log
  pos_file /var/log/fluentd-slurm.log.pos
  tag hpc.slurm
  format multiline
  format_firstline /^\[\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}\]/
  format1 /^\[(?<time>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3})\] \[(?<level>\w+)\] (?<message>.*)/
  time_format %Y-%m-%dT%H:%M:%S.%L
</source>

# Energy monitoring logs
<source>
  @type tail
  path /var/log/hpc/energy/*.log
  pos_file /var/log/fluentd-energy.log.pos
  tag hpc.energy
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S
</source>

# Thermal monitoring logs
<source>
  @type tail
  path /var/log/hpc/thermal/*.log
  pos_file /var/log/fluentd-thermal.log.pos
  tag hpc.thermal
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S
</source>

# System logs
<source>
  @type systemd
  tag system
  path /var/log/journal
  matches [{ "_SYSTEMD_UNIT": "docker.service" }]
  read_from_head true
  strip_underscores true
</source>

# Prometheus metrics logs
<source>
  @type tail
  path /var/log/prometheus/*.log
  pos_file /var/log/fluentd-prometheus.log.pos
  tag monitoring.prometheus
  format none
</source>

# Grafana logs
<source>
  @type tail
  path /var/log/grafana/*.log
  pos_file /var/log/fluentd-grafana.log.pos
  tag monitoring.grafana
  format json
  time_key t
  time_format %Y-%m-%dT%H:%M:%S%z
</source>

# Filters for log processing

# Parse Docker logs
<filter docker.**>
  @type parser
  key_name log
  reserve_data true
  remove_key_name_field true
  <parse>
    @type json
  </parse>
</filter>

# Add hostname and environment info
<filter **>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    environment "#{ENV['API_ENV'] || 'production'}"
    hypervisor_type "#{ENV['HYPERVISOR_TYPE'] || 'unknown'}"
    cluster_name "#{ENV['CLUSTER_NAME'] || 'hpc-energy'}"
  </record>
</filter>

# Filter for error detection
<filter **>
  @type grep
  <regexp>
    key message
    pattern /(ERROR|CRITICAL|FATAL|Exception|Traceback)/i
  </regexp>
  tag error_logs
</filter>

# Parse energy metrics
<filter hpc.energy>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type regexp
    expression /^Energy: (?<energy_value>\d+\.\d+) (?<energy_unit>\w+), Job: (?<job_id>\d+), Node: (?<node_name>\w+)/
  </parse>
</filter>

# Parse thermal events
<filter hpc.thermal>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type regexp
    expression /^Thermal event: (?<event_type>\w+), Temperature: (?<temperature>\d+\.\d+)Â°C, Sensor: (?<sensor_name>\w+)/
  </parse>
</filter>

# Enrich Slurm job logs
<filter hpc.slurm>
  @type record_transformer
  enable_ruby true
  <record>
    log_type "slurm"
    parsed_time "${Time.parse(record['time']).to_f}"
  </record>
</filter>

# Rate limiting for high-volume logs
<filter hpc.**>
  @type sampling
  interval 10
  sample_rate 100
</filter>

# Output configurations

# Store all logs in files with rotation
<match **>
  @type copy
  
  # File output with rotation
  <store>
    @type file
    path /var/log/hpc/aggregated/hpc-energy
    time_slice_format %Y%m%d%H
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    compress gzip
    format json
    
    # Buffer configuration
    <buffer time>
      timekey 1h
      timekey_wait 10m
      flush_mode interval
      flush_interval 30s
      chunk_limit_size 256m
      queue_limit_length 128
    </buffer>
  </store>
  
  # Forward to external log aggregation (if configured)
  <store>
    @type forward
    require_ack_response true
    ack_response_timeout 30
    recover_wait 10s
    heartbeat_interval 1s
    phi_threshold 16
    hard_timeout 60s
    
    <server>
      name external_fluentd
      host "#{ENV['EXTERNAL_FLUENTD_HOST']}"
      port "#{ENV['EXTERNAL_FLUENTD_PORT'] || 24224}"
      weight 60
    </server>
    
    <secondary>
      @type file
      path /var/log/hpc/failed_forward
      format json
    </secondary>
    
    <buffer>
      flush_mode interval
      flush_interval 5s
      chunk_limit_size 2m
      queue_limit_length 32
    </buffer>
  </store>
  
  # Send to Elasticsearch (if ELK stack is enabled)
  <store>
    @type elasticsearch
    host "#{ENV['ELASTICSEARCH_HOST'] || 'elasticsearch'}"
    port "#{ENV['ELASTICSEARCH_PORT'] || 9200}"
    index_name hpc-energy-logs
    type_name _doc
    
    # Index template
    template_name hpc-energy
    template_file /fluentd/etc/elasticsearch_template.json
    
    # Buffer configuration
    <buffer>
      flush_mode interval
      flush_interval 10s
      chunk_limit_size 5m
      queue_limit_length 32
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>
</match>

# Error logs routing
<match error_logs>
  @type copy
  
  # Store error logs separately
  <store>
    @type file
    path /var/log/hpc/errors/error-logs
    time_slice_format %Y%m%d
    format json
    
    <buffer time>
      timekey 1d
      timekey_wait 10m
    </buffer>
  </store>
  
  # Send alerts for critical errors
  <store>
    @type http
    endpoint "#{ENV['ALERT_WEBHOOK_URL']}"
    http_method post
    format json
    
    <buffer>
      flush_mode immediate
    </buffer>
  </store>
</match>

# Metrics output for monitoring
<match monitoring.**>
  @type prometheus
  <metric>
    name fluentd_input_status_num_records_total
    type counter
    desc The total number of incoming records
    <labels>
      tag ${tag}
      hostname ${hostname}
    </labels>
  </metric>
  
  <metric>
    name fluentd_output_status_num_records_total
    type counter
    desc The total number of outgoing records
    <labels>
      tag ${tag}
      hostname ${hostname}
    </labels>
  </metric>
</match>

# Health check endpoint
<source>
  @type http
  port 9880
  bind 0.0.0.0
</source>

# Monitoring and debugging
<source>
  @type monitor_agent
  bind 0.0.0.0
  port 24220
</source>

# Log level configuration
<system>
  log_level "#{ENV['FLUENTD_LOG_LEVEL'] || 'info'}"
  suppress_repeated_stacktrace true
  emit_error_log_interval 30s
  suppress_config_dump true
  without_source true
  
  <log>
    format json
    time_format %Y-%m-%d %H:%M:%S %z
  </log>
</system>